<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Simplelinearregression</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="MSE Notes by Florian Bär"/><meta property="og:title" content="Simplelinearregression"/><meta property="og:description" content="MSE Notes by Florian Bär"/><meta property="og:url" content="https://florianbaer.github.io/dendron//notes/075b837rsccm9l0g0vdwt69/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2.3.2022"/><meta property="article:modified_time" content="2.3.2022"/><link rel="canonical" href="https://florianbaer.github.io/dendron//notes/075b837rsccm9l0g0vdwt69/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/d1ad9e75dd743084.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d1ad9e75dd743084.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-851c3983ee4bf085.js" defer=""></script><script src="/_next/static/chunks/framework-dc33c0b5493501f0.js" defer=""></script><script src="/_next/static/chunks/main-dba071e7620a7571.js" defer=""></script><script src="/_next/static/chunks/pages/_app-40d6c8ae77511beb.js" defer=""></script><script src="/_next/static/chunks/155-0a8d44b6408c244d.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-cf1f1f4b587fc42c.js" defer=""></script><script src="/_next/static/vePU5CX2x0B0c_WXOZJOO/_buildManifest.js" defer=""></script><script src="/_next/static/vePU5CX2x0B0c_WXOZJOO/_ssgManifest.js" defer=""></script><script src="/_next/static/vePU5CX2x0B0c_WXOZJOO/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout site-layout" style="margin-top:64px"><section class="ant-layout site-layout" style="flex-direction:row"><section class="ant-layout site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></section><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="simplelinearregression"><a aria-hidden="true" class="anchor-heading" href="#simplelinearregression"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Simplelinearregression</h1>
<h1 id="simple-linear-regression"><a aria-hidden="true" class="anchor-heading" href="#simple-linear-regression"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Simple linear regression</h1>
<p>we get the 95% <a title="Private" style="color: brown" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank">confidence interval (Private)</a> with the following formula: [<span class="math math-inline">\hat{\beta_1} - 2 * \text{se}(\hat{\beta_1}), \hat{\beta_1} + 2 * \text{se}(\hat{\beta_1})</span>]</p>
<p><span class="math math-inline">\epsilon = Y - (\beta_0 + \beta_1 * X)</span> cannot be measured since <span class="math math-inline">\beta_0</span> and <span class="math math-inline">\beta_1</span> are unknown.</p>
<p>Approximation for residuals for <span class="math math-inline">\epsilon</span> <strong>residuals</strong> <span class="math math-inline">r_i = y_i - (\beta_0 + \beta_1 * x_i)</span></p>
<p><a title="Private" style="color: brown" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank">RSE (Private)</a> Residual Standard Error = <span class="math math-inline">\text{RSE} = \sqrt{\frac{r_1^2 + ... + r_n^2}{n - 2}}</span></p>
<p>Prediction Interval = <span class="math math-inline">\text{se}(y_0)^2 = \sigma^2 (1 + \frac{1}{n}+ \frac{(x_0 - \bar{x}^2)}{\Epsilon_{i = 1}^2 (x_i - \bar{x})^2})</span></p>
<h1 id="model-assumptions-for-the-error-term"><a aria-hidden="true" class="anchor-heading" href="#model-assumptions-for-the-error-term"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Model Assumptions for the Error Term</h1>
<p><span class="math math-inline">\epsilon_i\text{ iid }\N(0,\sigma^2)</span></p>
<h2 id="aim-of-residual-analysis"><a aria-hidden="true" class="anchor-heading" href="#aim-of-residual-analysis"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Aim of residual analysis</h2>
<p>If the model contains errors - we get a starting point for further investigation to a better and more adapted model (explorative data analysis)</p>
<p><strong>RSE</strong> considered a measure of the <strong>lack of fit</strong> of a regression model to the data.
<strong><span class="math math-inline">R^2</span></strong> Statistic is defined as : <span class="math math-inline">R^2 = 1 - \frac{\Epsilon_{i = 1}^n (y_i - \hat{y_i})^2}{\Epsilon_{i = 1}^n (y_i - \bar{y_i})^2} = 1 - \frac{\text{variance left after regression fit}}{\text{total variance}}</span></p>
<p><span class="math math-inline">R^2</span> is always between 0 and 1 (0 is bad, 1 is a perfect model)</p>
<h1 id="correlation-coefficient-private"><a aria-hidden="true" class="anchor-heading" href="#correlation-coefficient-private"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a><a title="Private" style="color: brown" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank">Correlation Coefficient (Private)</a></h1>
<p><span class="math math-inline">r = Cor(X,Y) = \frac{\Epsilon_{i = 1}^n (x_i - \bar{x_i})(y_i - \bar{y_i})}{\sqrt(\Epsilon_{i = 1}^n (x_i - \hat{x_i})^2)\Epsilon_{i = 1}^n (y_i - \bar{y_i})^2)}</span></p>
<p>You can not use the Correlation because of Multiple Linear Regression</p>
<h1 id="diagnostics-tool-for-testing-model-assumption---tukey-anscombe-plot"><a aria-hidden="true" class="anchor-heading" href="#diagnostics-tool-for-testing-model-assumption---tukey-anscombe-plot"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Diagnostics Tool for Testing Model Assumption - Tukey-Anscombe-Plot</h1>
<p>Verify that <span class="math math-inline">E[\epsilon] = 0</span></p>
<h2 id="tukey-anscombe-plot"><a aria-hidden="true" class="anchor-heading" href="#tukey-anscombe-plot"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Tukey-Anscombe-Plot</h2>
<p>Do it by the use of the <strong>Tukey-Anscombe-Plot</strong></p>
<ul>
<li>Residuals ploted on the vertical axis</li>
<li>predicted values on the horizontal axis</li>
</ul>
<p>Values should be in a horizontal line at Residuals = 0</p>
<p>Simulate Points to get more points </p>
<p><img src="assets/images/tukey_ascom.png"></p>
<h2 id="scale-location-plot"><a aria-hidden="true" class="anchor-heading" href="#scale-location-plot"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Scale-Location Plot</h2>
<p>Use the Standardized residuals </p>
<h3 id="consequences-for-case-of-correlated-error-terms"><a aria-hidden="true" class="anchor-heading" href="#consequences-for-case-of-correlated-error-terms"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Consequences for case of correlated error terms</h3>
<ul>
<li>The standard errors that are computed for the estimated regression coefficients or the fitted values are based on the assumption of independent error terms <span class="math math-inline">\epsilon_i</span></li>
<li>If there is correlation among the error terms, then the estimated standard errors will tend to underestimate the true standard errors. As a result, confidence and prediction intervals will be narrower than they should be</li>
</ul>
<h1 id="outlier"><a aria-hidden="true" class="anchor-heading" href="#outlier"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Outlier</h1>
<p>An outlier is if a data point is very far away from the most of the data.
If we remove an outlier - we have a small effect on the <span class="math math-inline">\beta_0</span> and <span class="math math-inline">\beta_1</span> but the effects on the <strong>RSE</strong> and <span class="math math-inline">R^2</span> is large</p>
<h2 id="high-leverage-points"><a aria-hidden="true" class="anchor-heading" href="#high-leverage-points"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>High Leverage points</h2>
<p><img src="assets/images/high_leverage_points.png">
If we remove observation 41 - the red line is the correct point - so if we remove high leverage points, the impact on <span class="math math-inline">\beta_0</span> and <span class="math math-inline">\beta_1</span> is big.</p>
<h2 id="cooks-distance"><a aria-hidden="true" class="anchor-heading" href="#cooks-distance"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Cooks distance</h2>
<p><span class="math math-inline">\hat{y}_{-i}</span> obeservation if you remove the i-th value.
As higher the value of cooks distance is - the higher is the influence of the i-th data point on the dataset
If a cooks value higher than 1 is observed - the value is considered as dangerously influencual.</p>
<p><strong>Read more about Tukey first aid principles</strong></p>
<p><strong>If you discover outliers and high leverage points - do not just remove them - it could be an important discovery for a new and other model!!!</strong></p>
<ol>
<li>Check wether outlier has occured due to an error in data collecito or recording
<ol>
<li>If an error may have occured: omit the data point</li>
<li>if an error can be excluded: go to 2</li>
</ol>
</li>
<li>Attempt to transform predictor or response variables in order to make <em>disappear</em> the outlier. If no improvement go to 3.</li>
<li>Outlier occured due to an unusual random varianions: If such outlier affect parameter estimation too much, then the observation my be removed (<strong>needs to be mentioned in the reports</strong>)</li>
</ol></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#simple-linear-regression" title="Simple linear regression">Simple linear regression</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#model-assumptions-for-the-error-term" title="Model Assumptions for the Error Term">Model Assumptions for the Error Term</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aim-of-residual-analysis" title="Aim of residual analysis">Aim of residual analysis</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#correlation-coefficient" title="Correlation Coefficient">Correlation Coefficient</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#diagnostics-tool-for-testing-model-assumption---tukey-anscombe-plot" title="Diagnostics Tool for Testing Model Assumption - Tukey-Anscombe-Plot">Diagnostics Tool for Testing Model Assumption - Tukey-Anscombe-Plot</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#tukey-anscombe-plot" title="Tukey-Anscombe-Plot">Tukey-Anscombe-Plot</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#scale-location-plot" title="Scale-Location Plot">Scale-Location Plot</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#consequences-for-case-of-correlated-error-terms" title="Consequences for case of correlated error terms">Consequences for case of correlated error terms</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#outlier" title="Outlier">Outlier</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#high-leverage-points" title="High Leverage points">High Leverage points</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cooks-distance" title="Cooks distance">Cooks distance</a></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"075b837rsccm9l0g0vdwt69","title":"Simplelinearregression","desc":"","updated":1646226083451,"created":1646209121266,"custom":{},"fname":"mse.ss22.predmod.simplelinearregression","type":"note","vault":{"fsPath":"vault"},"contentHash":"26d6768a54445c590e604943a978b60b","links":[{"type":"wiki","from":{"fname":"mse.ss22.predmod.simplelinearregression","id":"075b837rsccm9l0g0vdwt69","vaultName":"vault"},"value":"confidence interval","alias":"confidence interval","position":{"start":{"line":2,"column":16,"offset":42},"end":{"line":2,"column":39,"offset":65},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"confidence interval"}},{"type":"wiki","from":{"fname":"mse.ss22.predmod.simplelinearregression","id":"075b837rsccm9l0g0vdwt69","vaultName":"vault"},"value":"RSE","alias":"RSE","position":{"start":{"line":8,"column":1,"offset":392},"end":{"line":8,"column":8,"offset":399},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"RSE"}},{"type":"wiki","from":{"fname":"mse.ss22.predmod.simplelinearregression","id":"075b837rsccm9l0g0vdwt69","vaultName":"vault"},"value":"Correlation Coefficient","alias":"Correlation Coefficient","position":{"start":{"line":23,"column":3,"offset":1239},"end":{"line":23,"column":30,"offset":1266},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"Correlation Coefficient"}}],"anchors":{"simple-linear-regression":{"type":"header","text":"Simple linear regression","value":"simple-linear-regression","line":7,"column":0,"depth":1},"model-assumptions-for-the-error-term":{"type":"header","text":"Model Assumptions for the Error Term","value":"model-assumptions-for-the-error-term","line":18,"column":0,"depth":1},"aim-of-residual-analysis":{"type":"header","text":"Aim of residual analysis","value":"aim-of-residual-analysis","line":21,"column":0,"depth":2},"correlation-coefficient":{"type":"header","text":"Correlation Coefficient","value":"correlation-coefficient","line":29,"column":0,"depth":1},"diagnostics-tool-for-testing-model-assumption---tukey-anscombe-plot":{"type":"header","text":"Diagnostics Tool for Testing Model Assumption - Tukey-Anscombe-Plot","value":"diagnostics-tool-for-testing-model-assumption---tukey-anscombe-plot","line":34,"column":0,"depth":1},"tukey-anscombe-plot":{"type":"header","text":"Tukey-Anscombe-Plot","value":"tukey-anscombe-plot","line":36,"column":0,"depth":2},"scale-location-plot":{"type":"header","text":"Scale-Location Plot","value":"scale-location-plot","line":48,"column":0,"depth":2},"consequences-for-case-of-correlated-error-terms":{"type":"header","text":"Consequences for case of correlated error terms","value":"consequences-for-case-of-correlated-error-terms","line":52,"column":0,"depth":3},"outlier":{"type":"header","text":"Outlier","value":"outlier","line":56,"column":0,"depth":1},"high-leverage-points":{"type":"header","text":"High Leverage points","value":"high-leverage-points","line":60,"column":0,"depth":2},"cooks-distance":{"type":"header","text":"Cooks distance","value":"cooks-distance","line":64,"column":0,"depth":2}},"children":[],"parent":"0iypn97vbmjn2h03gkojb0i","data":{}},"body":"\u003ch1 id=\"simplelinearregression\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#simplelinearregression\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eSimplelinearregression\u003c/h1\u003e\n\u003ch1 id=\"simple-linear-regression\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#simple-linear-regression\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eSimple linear regression\u003c/h1\u003e\n\u003cp\u003ewe get the 95% \u003ca title=\"Private\" style=\"color: brown\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\"\u003econfidence interval (Private)\u003c/a\u003e with the following formula: [\u003cspan class=\"math math-inline\"\u003e\\hat{\\beta_1} - 2 * \\text{se}(\\hat{\\beta_1}), \\hat{\\beta_1} + 2 * \\text{se}(\\hat{\\beta_1})\u003c/span\u003e]\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\\epsilon = Y - (\\beta_0 + \\beta_1 * X)\u003c/span\u003e cannot be measured since \u003cspan class=\"math math-inline\"\u003e\\beta_0\u003c/span\u003e and \u003cspan class=\"math math-inline\"\u003e\\beta_1\u003c/span\u003e are unknown.\u003c/p\u003e\n\u003cp\u003eApproximation for residuals for \u003cspan class=\"math math-inline\"\u003e\\epsilon\u003c/span\u003e \u003cstrong\u003eresiduals\u003c/strong\u003e \u003cspan class=\"math math-inline\"\u003er_i = y_i - (\\beta_0 + \\beta_1 * x_i)\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca title=\"Private\" style=\"color: brown\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\"\u003eRSE (Private)\u003c/a\u003e Residual Standard Error = \u003cspan class=\"math math-inline\"\u003e\\text{RSE} = \\sqrt{\\frac{r_1^2 + ... + r_n^2}{n - 2}}\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003ePrediction Interval = \u003cspan class=\"math math-inline\"\u003e\\text{se}(y_0)^2 = \\sigma^2 (1 + \\frac{1}{n}+ \\frac{(x_0 - \\bar{x}^2)}{\\Epsilon_{i = 1}^2 (x_i - \\bar{x})^2})\u003c/span\u003e\u003c/p\u003e\n\u003ch1 id=\"model-assumptions-for-the-error-term\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#model-assumptions-for-the-error-term\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eModel Assumptions for the Error Term\u003c/h1\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\\epsilon_i\\text{ iid }\\N(0,\\sigma^2)\u003c/span\u003e\u003c/p\u003e\n\u003ch2 id=\"aim-of-residual-analysis\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#aim-of-residual-analysis\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eAim of residual analysis\u003c/h2\u003e\n\u003cp\u003eIf the model contains errors - we get a starting point for further investigation to a better and more adapted model (explorative data analysis)\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRSE\u003c/strong\u003e considered a measure of the \u003cstrong\u003elack of fit\u003c/strong\u003e of a regression model to the data.\n\u003cstrong\u003e\u003cspan class=\"math math-inline\"\u003eR^2\u003c/span\u003e\u003c/strong\u003e Statistic is defined as : \u003cspan class=\"math math-inline\"\u003eR^2 = 1 - \\frac{\\Epsilon_{i = 1}^n (y_i - \\hat{y_i})^2}{\\Epsilon_{i = 1}^n (y_i - \\bar{y_i})^2} = 1 - \\frac{\\text{variance left after regression fit}}{\\text{total variance}}\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003eR^2\u003c/span\u003e is always between 0 and 1 (0 is bad, 1 is a perfect model)\u003c/p\u003e\n\u003ch1 id=\"correlation-coefficient-private\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#correlation-coefficient-private\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003ca title=\"Private\" style=\"color: brown\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\"\u003eCorrelation Coefficient (Private)\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003er = Cor(X,Y) = \\frac{\\Epsilon_{i = 1}^n (x_i - \\bar{x_i})(y_i - \\bar{y_i})}{\\sqrt(\\Epsilon_{i = 1}^n (x_i - \\hat{x_i})^2)\\Epsilon_{i = 1}^n (y_i - \\bar{y_i})^2)}\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eYou can not use the Correlation because of Multiple Linear Regression\u003c/p\u003e\n\u003ch1 id=\"diagnostics-tool-for-testing-model-assumption---tukey-anscombe-plot\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#diagnostics-tool-for-testing-model-assumption---tukey-anscombe-plot\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eDiagnostics Tool for Testing Model Assumption - Tukey-Anscombe-Plot\u003c/h1\u003e\n\u003cp\u003eVerify that \u003cspan class=\"math math-inline\"\u003eE[\\epsilon] = 0\u003c/span\u003e\u003c/p\u003e\n\u003ch2 id=\"tukey-anscombe-plot\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#tukey-anscombe-plot\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eTukey-Anscombe-Plot\u003c/h2\u003e\n\u003cp\u003eDo it by the use of the \u003cstrong\u003eTukey-Anscombe-Plot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eResiduals ploted on the vertical axis\u003c/li\u003e\n\u003cli\u003epredicted values on the horizontal axis\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eValues should be in a horizontal line at Residuals = 0\u003c/p\u003e\n\u003cp\u003eSimulate Points to get more points \u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"assets/images/tukey_ascom.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"scale-location-plot\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#scale-location-plot\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eScale-Location Plot\u003c/h2\u003e\n\u003cp\u003eUse the Standardized residuals \u003c/p\u003e\n\u003ch3 id=\"consequences-for-case-of-correlated-error-terms\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#consequences-for-case-of-correlated-error-terms\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eConsequences for case of correlated error terms\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eThe standard errors that are computed for the estimated regression coefficients or the fitted values are based on the assumption of independent error terms \u003cspan class=\"math math-inline\"\u003e\\epsilon_i\u003c/span\u003e\u003c/li\u003e\n\u003cli\u003eIf there is correlation among the error terms, then the estimated standard errors will tend to underestimate the true standard errors. As a result, confidence and prediction intervals will be narrower than they should be\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"outlier\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#outlier\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eOutlier\u003c/h1\u003e\n\u003cp\u003eAn outlier is if a data point is very far away from the most of the data.\nIf we remove an outlier - we have a small effect on the \u003cspan class=\"math math-inline\"\u003e\\beta_0\u003c/span\u003e and \u003cspan class=\"math math-inline\"\u003e\\beta_1\u003c/span\u003e but the effects on the \u003cstrong\u003eRSE\u003c/strong\u003e and \u003cspan class=\"math math-inline\"\u003eR^2\u003c/span\u003e is large\u003c/p\u003e\n\u003ch2 id=\"high-leverage-points\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#high-leverage-points\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eHigh Leverage points\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"assets/images/high_leverage_points.png\"\u003e\nIf we remove observation 41 - the red line is the correct point - so if we remove high leverage points, the impact on \u003cspan class=\"math math-inline\"\u003e\\beta_0\u003c/span\u003e and \u003cspan class=\"math math-inline\"\u003e\\beta_1\u003c/span\u003e is big.\u003c/p\u003e\n\u003ch2 id=\"cooks-distance\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#cooks-distance\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCooks distance\u003c/h2\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\\hat{y}_{-i}\u003c/span\u003e obeservation if you remove the i-th value.\nAs higher the value of cooks distance is - the higher is the influence of the i-th data point on the dataset\nIf a cooks value higher than 1 is observed - the value is considered as dangerously influencual.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRead more about Tukey first aid principles\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIf you discover outliers and high leverage points - do not just remove them - it could be an important discovery for a new and other model!!!\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCheck wether outlier has occured due to an error in data collecito or recording\n\u003col\u003e\n\u003cli\u003eIf an error may have occured: omit the data point\u003c/li\u003e\n\u003cli\u003eif an error can be excluded: go to 2\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eAttempt to transform predictor or response variables in order to make \u003cem\u003edisappear\u003c/em\u003e the outlier. If no improvement go to 3.\u003c/li\u003e\n\u003cli\u003eOutlier occured due to an unusual random varianions: If such outlier affect parameter estimation too much, then the observation my be removed (\u003cstrong\u003eneeds to be mentioned in the reports\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ol\u003e","noteIndex":{"id":"ofsa5s7zh7imqa042iv23kt","title":"Root","desc":"","updated":1646324578684,"created":1646295077431,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"e57e6d83473ba1b3392e09a272ee2ff4","links":[],"anchors":{"welcome-to-dendron":{"type":"header","text":"Welcome to Dendron","value":"welcome-to-dendron","line":7,"column":0,"depth":1},"lookup":{"type":"header","text":"Lookup","value":"lookup","line":11,"column":0,"depth":2}},"children":["vrc7o3pbnmcqgfwbbxyx8em","mh229sp8x9xv0ubu056s94w"],"parent":null,"data":{},"body":"# Welcome to Dendron\n\nThis is the root of your dendron vault. If you decide to publish your entire vault, this will be your landing page. You are free to customize any part of this page except the frontmatter on top.\n\n## Lookup\n\nThis section contains useful links to related resources.\n\n- [Getting Started Guide](https://link.dendron.so/6b25)\n- [Discord](https://link.dendron.so/6b23)\n- [Home Page](https://wiki.dendron.so/)\n- [Github](https://link.dendron.so/6b24)\n- [Developer Docs](https://docs.dendron.so/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{}},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"seeds":{}},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","siteUrl":"https://florianbaer.github.io/dendron/","seo":{"title":"Dendron","description":"MSE Notes by Florian Bär"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enablePrettyLinks":true,"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"075b837rsccm9l0g0vdwt69"},"buildId":"vePU5CX2x0B0c_WXOZJOO","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>