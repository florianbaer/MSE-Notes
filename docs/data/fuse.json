{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title"},{"path":["body"],"id":"body","weight":1,"src":"body"}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Root","n":1},"1":{"v":"# Welcome to Dendron\n\nThis is the root of your dendron vault. If you decide to publish your entire vault, this will be your landing page. You are free to customize any part of this page except the frontmatter on top.\n\n## Lookup\n\nThis section contains useful links to related resources.\n\n- [Getting Started Guide](https://link.dendron.so/6b25)\n- [Discord](https://link.dendron.so/6b23)\n- [Home Page](https://wiki.dendron.so/)\n- [Github](https://link.dendron.so/6b24)\n- [Developer Docs](https://docs.dendron.so/)\n","n":0.132}}},{"i":2,"$":{"0":{"v":"Mse","n":1}}},{"i":3,"$":{"0":{"v":"Ss22","n":1}}},{"i":4,"$":{"0":{"v":"Privlaw","n":1}}},{"i":5,"$":{"0":{"v":"Tutorial","n":1}}},{"i":6,"$":{"0":{"v":"Sw01","n":1},"1":{"v":"\n\n# Case 1\n\n> As engineer you’re responsible for the evaluation of a new heating system for your industrial plant. Any legal requirements?\n\nYes indeed. First of all I must do my job with \"due diligence\" while doing the evalution. Then I must follow the standards that nobody gets hurt while operating these systems when they will be installed. Further I can not prefer a company where I have a friend of mine working at without objective reason.\n\n# Case 2\nYou developed an injection moulding machine that produces „tailor-made“ plastic eye lenses. The process needs a sub-millimetre handling. To achieve that you use an optical camera. The producer of the camera developed for that specific machine an optical recognition software.\n> Which main legal problems can you recognise? Discussion.\n\nWhat happens if the camera breaks or is wrongly calibrated and a user of these plastic lenses gets hurt? \nFurther you have to ensure you get all the medical certifications needed for the country you want to sell these lenses. What if you don't do the certifications?\n\n# Case 3\nGoogle Maps shows the actual traffic situation. You plan to use this information to categorise areas that are noisier and therefore real estates have a low worth. You integrate this information into your platform and sell it online.\n> Any legal questions?\n\nThe data obtained by google is proably owned by google, so you can not sell data collected by google services without their grant. I think Google could bring you to justice for this use of their data.\n\n# Case 4\nIn your development and testing of a medical device you collect a lot of sensitive medical data. Accidentally you find out that your colleague uses this data to train his AI-algorithm.\n\n> What do you think? \n\nI guess you can't just take data out of a testing device for you own machine learning models. First you have to ask the producer of the medical devices if you could provide you with the data for this device. Further the patients which provide (probably without knowing) the data have to accept that their data is used for training an online machine learning model. \n","n":0.053}}},{"i":7,"$":{"0":{"v":"Why privacy and law","n":0.5},"1":{"v":"\n# Why privacy and law\nFor companies it is a huge **reputation risk** if they misuse personal data!\n\nBig change incoming with the new privacy law (GDPR - General Data Protection Regulation)\n\n# Data Protection\n- is defined as the protection of personal integrity agains infringements (Civil Law - ZGB Art. 28)\n- **established** the second half of the 20th century\n- means\n  - informational **self-determination**\n  - protection of the **personality** in the data-processing\n  - protection of **privacy**\n  - protection form **abusive data processing**\n\n\n- [ ] insert theory of spheres\n\n\nAny infringement (Verletzung) of the integrity/personality is illegal unless it is justified by the consent of the person whose rights are infringed or by law or by an overriding private or public interest\nThen you could go to the court\n\n- Swiss Federal Act on Data Protection (DSG) will come into force in 2022.\n- Canton and communal: Every canton has its own flavor.\n\nNew Data Protection law only applies to natural persons by \n- natural persons (**natural and juristic personen!!!**)\n- federal bodies\n\nIt does not apply to\n- personal data that is processed by a naturla person _exclusivly for personal use_ and which is not _disclosed to outsiders_\n- deliberations of the federal assembly and in parliamentary committees\n\nRecording is different - see privacy notice in teams\n\n# Territorial scope\nSwiss law is now applicable in foreign coutnries! **Marktortprinzip**\n> **This act is applicable to fact patterns that have an effect in switzerland, _even if they occured abroad_ !!!**\n\n# **revDSG**\n## **Article 5** - definitions\n- personal data\n- data subject\n- sensitive personal data\n- processing\n- **Controller** private person (human or company) that decides on the purpose and the means of the processing - **so not the processor is the controller but their boss/company which gave the order to process the data**\n- **processor**\n\nData must be destroyed when it is no longer needed regarded to the purpose (e.g. apply for a new job)\n\nAnyone who processes personal data must ascertain that the data is accurate. \n\nExample:\nMiss Florian Bär $\\to$ i have the right that this data is corrected!!\n\nYou have to inform the people how you use their data!\n\n## Proportionate\n\nDo the reason of the collected personal data justify the penetraion in ones privacy?\n\nImportant regarding websites - Cookie Buttons must look the same - you can not guide the use one of the buttons.\n\n## data security\nthe controller and the processor must ensure (sich versichern) with adequate technical and organisational measures, security concerns are addressed!\n\n## inventory of processing activities\ncontroller and processor keep an inventroy of their processing activities\n\n## notification\nThe controller shall notify the FDPIC (Datenschutzbeauftragter) as soon as possible after a security breach\n\n# access rights (Art. 25 revDSG)\n- send the data back and destroy all the data\n  \nAnybody has the right when personal data of him is collected and for what purpose it is used\n- for how long\n- how as access\n- purpose\n\nactual data protection law goes further than the new DSG\n\n\n\n## limitations\nthe controller has the right refuse, restrict or defer provision of information\n- is manifestly nfounded in particular if it pursues a purpose that is contrary to data protection or is obviously of a frivolous nature!\n\nThe data subject shall receive the information required in order to enable him to assert his rights under this Act and to ensure the transparent processing of data.\n- **in 30 day**\n- **free of charge**\n\n\nAny person may request from the controller, free of charge, the disclosure of the personal data that he has isclosed to him in a standard electronic format if:\n- the controller processes the data in an automated manner; and\n\n# Sactions / Penalties\nFines up to 250'000 Swiss Francs are quite small compared to other european countries!\n\n328b OR (code of obligation)\n- The employer may data about the employee only process as it concerns his qualification for the employment or are inevitable for the execution of the employment. The regulations of the Swiss Data Protection Act are applicable.\n\n# Simple case\n> Nova-AG, headquartered in Dornbirn (AT), has developed a software that enables large companies to automatically analyse the absences of their employees. HR managers automatically receive profiles of their employees and their absences through the system and can thus intervene in a supportive manner. Nova AG has a subsidiary in Switzerland, which sells the software and the service hosted in Austria.\n>\n What is the data protection situation?\n\n\nSwiss Emplyoees are protected by the revDSG and austrian employees are protected by the GPDR.\n\n","n":0.038}}},{"i":8,"$":{"0":{"v":"Introduction","n":1},"1":{"v":"\n# Introduction [[PrivLaw]] [[MSE]]\ns\n## Why law?\nLaw are not only books - there are agreements for rules as well.\n\nLaw is social framework \nRules save energy - compared to Parents and children\nWithout **Risk** - most businesses are not successful.\nLawyer should not only support one side - more find the best solution for both sides of a given problem.\nIn technical projects legal support is necessary as early as possible! Otherwise they might be **shot off** in the very last minute!\nBy law the management is personally responsible to organise & control the legal compliance! (Art. 754 OR)\n\n# Privacy and data protection\nPrivacy and the right to forget is essential to develop personally (without social control)\nIt protects people\nWe spread data everywhere with the risk for loosing reputation.\nPersonal data has a financial worth.\nYoung generations are more sensitive to privacy than the boomers.\n\n![](assets/images/SW01_Contracts.png)\nYou have to check in an early stage which law fields are touched and where you can adapt (if it is not already strictly regulated and stirctly defined)\n\nA statement must be justified by an article and proof it with evidence $X = f_{\\text{(Art. XXX) + (evidence YYY)}}$\n**It is not enought to say which article is important, say as well why and because of which evidence you state you argument**\n\n# Spearation of powers\n1. Legislative (people, parliament) $\\to$ Club members\n2. Executive (BR, RR, authorities) $\\to$ Vorstand\n3. Judiciary (courts) $\\to$ Controllers (Kontrollstelle)\n\nClubs are organized the same way (see above)\n\n**In reality the ececutive has large discretion** as long as nobody appeal against order (large possibility to adapt and decide)\n\n# Switzerland\n- The people and the cantons building the swiss confederation and not vice-versa\n- Cantons are in their power of legislation $\\text{\\underline{superior}}$ to the swiss confederation - its not top down, its bottem up (cantons to Country)\n- **public authority is only entitled to legislate and act in a territory if it is $\\underline{\\text{\\textbf{explicitly constitutional legitimation}}}$**\n\n![hierarchy of law](assets/images/SW01_hierarchy_of_law.png)\nDecree & Law means $\\to$ Verordnung and Gesetzt\n\n![civil and public law](assets/images/SW01_civil_and_public_law.png)\n\nCivil law is for Contracts\npublic law is for StGB,FMG,BÜPF/VÜPF,ElDI-V u.a.m.\n\n# private / public Law\nCivil law is mastered by **principle of freedom** of coalition & freedom\n\nYou have to recognize if you touch civil law or public law (ignore crime law at the moment)\n\nBy-LAW (Verordnung) $\\ne$ order (Verfügung)\n**Burden of proof** $\\to$ you have to proof it !!\n**if it becomes complicated - start to produce paper (mails, pictures, ask for names etc.) IT MUST BE USED AS PROOVE**\n\nThe **IPRG (Gesezt über das internationale Privatrecht)** is the gateway between swiss & foreign law.\n\nCivil law - the court will ask about an advance on court costs $\\to$ if you ask for millions, the cost in advance will be higher.\n\nHowever looses a civil case - you must pay:\n- court cost\n- other party costs (lawyer)\n- and your own costs\n\nif you win the process - you don't have the money yet. Opposite party can go into bankruptcy\n\n","n":0.046}}},{"i":9,"$":{"0":{"v":"Predmod","n":1}}},{"i":10,"$":{"0":{"v":"Simplelinearregression","n":1},"1":{"v":"# Simple linear regression\nwe get the 95% [[confidence interval]] with the following formula: [$\\hat{\\beta_1} - 2 * \\text{se}(\\hat{\\beta_1}), \\hat{\\beta_1} + 2 * \\text{se}(\\hat{\\beta_1})$]\n\n$\\epsilon = Y - (\\beta_0 + \\beta_1 * X)$ cannot be measured since $\\beta_0$ and $\\beta_1$ are unknown.\n\nApproximation for residuals for $\\epsilon$ **residuals** $r_i = y_i - (\\beta_0 + \\beta_1 * x_i)$\n\n[[RSE]] Residual Standard Error = $\\text{RSE} = \\sqrt{\\frac{r_1^2 + ... + r_n^2}{n - 2}}$\n\nPrediction Interval = $\\text{se}(y_0)^2 = \\sigma^2 (1 + \\frac{1}{n}+ \\frac{(x_0 - \\bar{x}^2)}{\\Epsilon_{i = 1}^2 (x_i - \\bar{x})^2})$\n\n# Model Assumptions for the Error Term\n$\\epsilon_i\\text{ iid }\\N(0,\\sigma^2)$\n\n## Aim of residual analysis\nIf the model contains errors - we get a starting point for further investigation to a better and more adapted model (explorative data analysis)\n\n**RSE** considered a measure of the **lack of fit** of a regression model to the data. \n**$R^2$** Statistic is defined as : $R^2 = 1 - \\frac{\\Epsilon_{i = 1}^n (y_i - \\hat{y_i})^2}{\\Epsilon_{i = 1}^n (y_i - \\bar{y_i})^2} = 1 - \\frac{\\text{variance left after regression fit}}{\\text{total variance}}$\n\n$R^2$ is always between 0 and 1 (0 is bad, 1 is a perfect model)\n\n# [[Correlation Coefficient]]\n$r = Cor(X,Y) = \\frac{\\Epsilon_{i = 1}^n (x_i - \\bar{x_i})(y_i - \\bar{y_i})}{\\sqrt(\\Epsilon_{i = 1}^n (x_i - \\hat{x_i})^2)\\Epsilon_{i = 1}^n (y_i - \\bar{y_i})^2)}$\n\nYou can not use the Correlation because of Multiple Linear Regression\n\n# Diagnostics Tool for Testing Model Assumption - Tukey-Anscombe-Plot\nVerify that $E[\\epsilon] = 0$\n## Tukey-Anscombe-Plot\nDo it by the use of the **Tukey-Anscombe-Plot**\n\n- Residuals ploted on the vertical axis\n- predicted values on the horizontal axis\n\nValues should be in a horizontal line at Residuals = 0\n\nSimulate Points to get more points \n\n![](assets/images/tukey_ascom.png)\n\n## Scale-Location Plot\n\nUse the Standardized residuals \n\n### Consequences for case of correlated error terms\n- The standard errors that are computed for the estimated regression coefficients or the fitted values are based on the assumption of independent error terms $\\epsilon_i$\n- If there is correlation among the error terms, then the estimated standard errors will tend to underestimate the true standard errors. As a result, confidence and prediction intervals will be narrower than they should be\n\n# Outlier\nAn outlier is if a data point is very far away from the most of the data.\nIf we remove an outlier - we have a small effect on the $\\beta_0$ and $\\beta_1$ but the effects on the **RSE** and $R^2$ is large\n\n## High Leverage points\n![](assets/images/high_leverage_points.png)\nIf we remove observation 41 - the red line is the correct point - so if we remove high leverage points, the impact on $\\beta_0$ and $\\beta_1$ is big.\n\n## Cooks distance\n$\\hat{y}_{-i}$ obeservation if you remove the i-th value.\nAs higher the value of cooks distance is - the higher is the influence of the i-th data point on the dataset\nIf a cooks value higher than 1 is observed - the value is considered as dangerously influencual.\n\n**Read more about Tukey first aid principles**\n\n\n**If you discover outliers and high leverage points - do not just remove them - it could be an important discovery for a new and other model!!!**\n\n1. Check wether outlier has occured due to an error in data collecito or recording\n   1. If an error may have occured: omit the data point\n   2. if an error can be excluded: go to 2\n2. Attempt to transform predictor or response variables in order to make _disappear_ the outlier. If no improvement go to 3.\n3. Outlier occured due to an unusual random varianions: If such outlier affect parameter estimation too much, then the observation my be removed (**needs to be mentioned in the reports**)\n\n","n":0.042}}},{"i":11,"$":{"0":{"v":"Pre Semester","n":0.707},"1":{"v":"[[PredMod]] [[MSE]]\n## Pre-Semster\n### Cumulative Distribution Function\nCumulative Distribution Function is defined as follows: $F(x) = P(X \\le x)$ where $X$ is the set of all possible values of the random variable and $x$ is the value of the random variable at which the CDF is to be evaluated. \nThis is needed to get a range of values e.g. $F(X \\in (a,b]) = P(a < X \\le b)$ which is defined as $F(b) - F(a)$. Important as well. The derivative $F'(x)$ **is always 0 or bigger**\n![Example CDF](assets/images/Example_CDF.png)\n\n### probability density Function\nThe probability density Function is defined as $f(x) = F'(x)$ which is the derivative of the CDF.\nThe PDF must always be **zero or positive** - as the CDF is always monotonically increasing.\n$P(a < X \\le b) = F(b) - F(a) = \\int_a^b f(x)dx$\n\n### expected value\nThe expected value $E(X)$ and the standard deviation $\\sigma_X$ have the same meaining in the discrete and the continuous case.\n$E(X) = \\int_{-\\infty}^{\\infty} x f(x) dx$ whereas $x$ is the outcome and $f(x) dx$ is the probability of the outcome.\n### variance \nThe variance $V(X)$ is defined as $V(X) = E(X^2) - E(X)^2$\n### quantiles\nThe quantiles are defined as $q(a) = 182.5$ which means that 75% of the values are smaller than $q(a)$ and 25% are larger than $q(a)$.\n\n# important continous distributions\n\n## Uniform Distribution\nThe uniform distribution is defined as follows:\n$$\nf(x) = \\left\\{\n    \\begin{array}{ll}\n        \\frac{1}{b-a} & if a \\le x \\le b \\\\\n        0 & else\n    \\end{array}\n\\right.\n$$\n`dunif(x = 5, min = 1, max = 10)` for the density of the uniform distribution at $x = 5$ from $1$ to $10$.\nTo get the probability of $P(1 \\le X \\le 5)$ use `punif(q = 5, min = 1, max = 10)`.\nTo generate random variables use the following code snippet: `runif(n = 5, min = 1, max = 10)`\n\n## Exponential Distribution\nThe exponential distribution is defined as follows:\n$exp(x) = e^x$\n$$\nf(x) = \\left\\{\n    \\begin{array}{ll}\n        \\lambda * exp(-\\lambda x) & if x \\geq 0 \\\\\n        0 & otherwise\n    \\end{array}\n\\right.\n$$\nwhere we write $X \\sim Exp(\\lambda)$\n![Samples of the exponential distribution](assets/images/ExponentialDistribution.png)\nAssuming $X \\sim Exp(3)$ for $P(0 \\le X \\le 4)$ with R it is calculated as follows `pexp(4, rate = 3)`\n\n### Poisson and Exponential Distribution\nThese two distributions are related. If the time elapsed between two failures of a system follows Exp($\\lambda$), then the number of failures during the period t follows Poisson($\\lambda * t$).\n$P(T > t) = P(T \\le t) = P(\\text{no decay in} [0,t]) = \\frac{(\\lambda t)^0 e^{-\\lambda t}}{0!} = e^{-\\lambda t}$\n\n## Normal distribution\nThis is the most important distribution: \n$f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} exp(-\\frac{(x - y)^2}{2 \\sigma^2 })$\nthe cumulative distirbution function cannot be explicitly expressed by formulas and must be calculated with software.\nIQ Example:\n$X \\sim \\mathcal{N}(100, 15^2)$ where 15 is the standard deviation.\nUse R to get the value `1 - pnorm(130, mean = 100, sd = 15) = 0.022` - therefore 2% is highly gifted.\n\n\n\n[[CDF]] [[PDF]] [[Expected Value]] [[Variance]] [[Quantiles]]\n","n":0.046}}},{"i":12,"$":{"0":{"v":"LinearRegression","n":1},"1":{"v":"# LinearRegression\nThere is an Output variable $Y$ and one or multiple Input variable $X_1,X_2,X_3$ which then looks as the following: $ Y = f(X_1, X_2, X_3) + \\epsilon $\n![Which model would you choose](assets/images/LinReg1_WhichModel.png)\n\nA cubic model is a linear model as well, as the $\\beta$ terms are linear $\\to$ $Y = \\beta_1 + \\beta_2 * X + \\beta_3 * X^3$\n\n$Y = \\Beta_0 + \\Beta_1 * X $ where $\\beta_0$ is the intercept and $\\beta_1$ is the slope.\n**residual sum of squares RSS** is defined as $\\text{RSS} = $\n**residuals** are defined as $r_i = y_i - \\hat{y}_i$\n\n**standard error** $\\to$ $se(\\hat{\\beta_0})^2 = \\sigma^2 (\\frac{1}{n} + \\frac{\\lineontop{x}^2}{\\sum_{i=1}^n (x_i - \\lineontop{x})^2})$\n\n$\\hat{\\sigma} = \\text{RSE} = \\sqrt{\\frac{RSS}{n-2}}$\n\n# T-Test\nHow many times the standard deviation away from zero must $\\hat{\\beta_1}$ from 0?\nIt follows a T-Distribution with $n-2$ degrees of freedom.\n","n":0.088}}},{"i":13,"$":{"0":{"v":"Introduction","n":1},"1":{"v":"# Introduction\n\nExample from Mr. Hubble - Calculate the age of the universe (SW01 - SW04)\nAnother example is the Classification (SW05-SW10)\nOr Analysis of Time Series (SW11-SW14)\n\n","n":0.2}}},{"i":14,"$":{"0":{"v":"Delearn","n":1}}},{"i":15,"$":{"0":{"v":"Learningandoptimization","n":1},"1":{"v":"# Learning and Optimization\n\nTarget for this week: Gradient Descent / stochastic gradient descent\n\n\n## General Regression Problem\n\nLearning a numeric value from a set of datapoints.\n\n## Classification Problem\n\nClassification of a set of datapoints into a set of classes.\n\nFull Batch Gradient Descent\nMini-Batch Gradient Descent or Stochastic Gradient Descent\n- You need to make the learning rate smaller with stochastic gradient descent\n- Less epochs needed - as per Batch the calculation is done\n- Calculation-Time is increaed per Epoch, as calculation is done per batch\n\n## Hyperparameters\n- Batch Size\n  - $\\epsilon \\sim \\frac{1}{\\sqrt{\\text{batchsize}}}$\n- Learning rate\n  - $\\epsilon \\sim \\alpha$\n\nError bars scale with the learning rate $\\alpha$\n\nWatch `torch.nn.CrossEntropyLoss`\n\n# ToDos\n- [ ] Watch the math behind DeLearn","n":0.096}}},{"i":16,"$":{"0":{"v":"Introduction","n":1},"1":{"v":"# Introduction\n\n[[MSE]] [[DeLearn]]\n## What is ML ?\n1. Learning from data\n\n## Why do we need ML?\n1. We dont know the rules\n2. where math stops\n3. very complex problems\n\n## ML apps?\n1. Object detection\n2. Generate new data\n3. High dimensional data (images, sound)\n\n## DL $\\neq$ ML?\n1. DL is learning from feature extraction\n2. DL is a part of ML\n\n## Dangers of DL?\n1. Biased data\n2. AI explainability\n3. Don't rely to much on the models\n\n# Definitions\n> Machine learning consists computer methods that analyse observation data to automatically detect patterns, and then use the uncovered patterns to perform tasks based on new unobserved data.\n\n> “[Machine Learning is the] fi eld of study that gives computers the ability to learn without being explicitly programmed.” - Arthur Samuel, 1959\n\n> Machine Learning could be defi ned as a set of methods that automatically detect patterns in data, and then use the uncovered patterns to predict future data, or to perform other kinds of decision making under uncertainty. - Machine Learning – A Probabilistic Perspective, K. Murphy, 2012.\n\n> A machine learning program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. - Machine Learning, T. Mitchell, 1997.\n\n![Workflow repetitions in MachineLearning](assets/images/DeLearn_1_RepeateLearning.png)\n\n## Supervised Machine Learning \n> With supervised learning, the goal is to extract some relevant features x from raw observation data o and to learn a mapping from inputs x to outputs y given a set of example data called the training set. \n\n![Introduction](assets/images/Introduction_HowProceed.png)\n\n**PROBLEM 1**: We need large quantities of human validated examples! …and this is costly to build\n\n**PROBLEM 2**: Because of the variabilities, we will need even more data and the mapping functions need to capture more complexities. \n\n**PROBLEM 3**: We usually spend a lot of time to hand-craft interesting compact features, this is called feature engineering\n\n","n":0.057}}},{"i":17,"$":{"0":{"v":"Datamgnt","n":1}}},{"i":18,"$":{"0":{"v":"Introduction","n":1},"1":{"v":"[[MSE]] Topic: [[DataMgmt]]\n\n# Poliglot Persistence\nYou should use different Databases to takle different Problems. \n\n![Poli](assets/images/Poliglot_Persistence.png)\n\n- Polyglot persistence is about using different data storage technologies to handle varying data storage needs.\n- Polyglot persistence can apply across an enterprise or within a single application.\n- Encapsulating data access into services reduces the impact of data storage choices on other parts of a system.\n- Adding more data storage technologies increases complexity in programming and operations, so the advantages of a good data storage fit need to be weighed against this complexity.\n","n":0.108}}},{"i":19,"$":{"0":{"v":"Datamgmt","n":1}}},{"i":20,"$":{"0":{"v":"Sw01","n":1},"1":{"v":"# Postgres \nIs a post-relational extensinble DBMS - similar to oracle, ms sql server, ingers. Close to SQL standard but \"conservative\" \nwith special types for e.g. spatial data etc...\nAnd even further extensible with extensions (e.g. PostGIS)\n- **Good total costs of ownership**\n- Not so good mobile mobile sync\n- Not so good html form generator\n\n\n[[mse.ss22.datamgmt.cte]]\n\n[[mse.ss22.datamgmt.arraytypes]]\n","n":0.137}}},{"i":21,"$":{"0":{"v":"Cte","n":1},"1":{"v":"# Common Table Expressions\n\nCTE can be used with recursive clause to deal with hierarchical or tree structured data.\n``` sql\nWITH movies_etp AS (\nSELECT * from movies WHERE name ilike ‘P%’\n),\n--tmp2 AS (\n--…\n--)\nSELECT * from movies_etp ORDER BY name;\n\n```\n\nfor recursive calls:\n```sql\nWITH RECURSIVE query_name [ (column_name [,...]) ] AS (\n-- non-recursive term\nSELECT …\nUNION ALL\n-- recursive term\nSELECT …\n)\nSELECT ...;\n```\n\nA datatype defines possible values - e.g. Int = integer numbers but defines as well how data is stored and indexed.\nContains as well constructors, operators, functions and optimizers (with index extensions)\n\n","n":0.108}}},{"i":22,"$":{"0":{"v":"Arraytypes","n":1},"1":{"v":"\n# Array types\n- Arrays are a sort of collections\n- They have a fixed or variable size\n  \nIn pg - any datatype can be stored as array and are **index 1 based**!\n\n```sql\nCREATE TABLE sal_emp ( \n    name text, \n    pay_by_quarter integer[], \n    schedule text[][]  -- two dimensional array\n);\n\n\nINSERT INTO sal_emp VALUES (\n'Bill', \nARRAY[10000, 10000, 10000, 10000], \nARRAY[['meeting', 'lunch'], \n['training', 'presentation']]\n); \n\n-- Works as well\nSELECT ARRAY[1,2,3+4]; \n-- returns an array with values {1,2,7}\n\n\n-- equal: =\nSELECT ARRAY[1,3] = ARRAY[1,3];\nSELECT ARRAY[1.1,2.1,3.1]::int[] = ARRAY[1,2,3];\nSELECT ARRAY[3,1] = ARRAY[1,3]; -- !!\n-- is contained by: <@\nSELECT ARRAY[3,1] <@ ARRAY[1,3]; -- !! \nSELECT ARRAY[2,7] <@ ARRAY[1,7,4,2,6];\n-- overlap - have at least one element in common: &&\nSELECT ARRAY[1,4,3] && ARRAY[2,1];\n-- ANY syntax\nSELECT * FROM sal_emp\nWHERE 30000 = ANY (pay_by_quarter); \n\n\n--- is the value 3 and 77 and 1 in the array 3,1,4\nSELECT ARRAY[3,77,1] <@ ARRAY[3,1,4];\n-- will output false!\n\n```\n\n\n","n":0.085}}},{"i":23,"$":{"0":{"v":"Antede","n":1}}},{"i":24,"$":{"0":{"v":"Textclassification","n":1},"1":{"v":"# Text Classification\nSentitment analysis is not simple text classification\n\n- Lot of people still do hand coded rules to classify text: Needs a lot of work (expert knowledge)\n- Supervised machine learning (Labeling is required)\n  - Learn the relationship between text and label\n\n- a set of document $D$\n- a fixed set of $N$ classes $C$\n- a training set of $M$ hand-labeled documents ($d_1$, $c_1$), . . . ,($d_M, c_M$)\n\n- a mapping $D \\to C$ that associates a predicted class $c \\in C$ to each\ndocument $d \\in D$\n\n- Naïve Bayes\n- Logistic regression\n- Support-vector machines (SVM)\n- k-Nearest Neighbors\n\n![Naïve Bayes concept](/assets/images/2022-03-03-09-28-57.png)\nIts called naive because it assumes that the features are independent of each other. \n![Bayes theorem](/assets/images/2022-03-03-09-31-50.png)\n\n[[MAPClassifier]] is also called maximum a posteriori (MAP) classifier.\n\n$argmax_{c \\in C} \\frac{P(d|c)P(c)}{P(d)} = argmax_{c \\in C} P(d|c)P(c)$\n\nBernoulli model (if word is in document) or multinominal model when $f_i$ is a count of the number of times the word $i$ appears in the document.\n\nNaive bayes is the probability of class c with the product of conditioanl probabilities of each word in the document.\n\n$$c_{nb} = \\text{arg max}_{c \\in C} P(c) \\product_{k = 1}^N P(x_k | c)$$\n\n**Slide 18** every class observed $\\frac{1}{3}$\n","n":0.073}}}]}
